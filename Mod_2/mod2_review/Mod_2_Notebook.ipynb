{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 2 Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Your Data â€¦ Quickly\n",
    "The first thing you want to do when you get a new dataset, is to quickly to verify the contents with the .head() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5043, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n",
       "       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n",
       "       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n",
       "       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n",
       "       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n",
       "       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n",
       "       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n",
       "       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_metadata.csv')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "A Hollywood executive whats to know how much a R-Rated movie released after 2000 will earn. The data above is a sample of some of the movies with that ranting during that time frame, as well as other movies. How would you go about answering her question? Talk through it theoretically and then do it in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First clean the data to find the R rated movies with revenue, find the profits by adding a colum that is the gross - budget. Make sure nan values are not counted in n and in those profits or budgets with nan values when subtracting them. Using a 95% level of confidence or significance of 0.025 to find the two tail z test with a total alpha of 0.05 and divide by 2 to find the min and max confidence intervals. ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "mean  = df[(df['title_year']>2000) &(df['content_rating']=='R')]['gross'].mean()\n",
    "\n",
    "stddev  = df[(df['title_year']>2000) &(df['content_rating']=='R')]['gross'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df[(df['title_year']>2000) &(df['content_rating']=='R')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df[(df['title_year']>2000) &(df['content_rating']=='R')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25593896.732384615, 25593896.732384615)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus = mean - 1.96*(stddev/n**.5)\n",
    "plus = mean - 1.96*(stddev/n**.5)\n",
    "plus, minus\n",
    "\n",
    "\n",
    "#-48965307.24992396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25197269.346510723, 30100427.52931709)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.t.interval(alpha = 0.05, \n",
    "                df = len(_df)-1,\n",
    "                 loc = mean,\n",
    "                 scale = stddev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confidence interval at 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if there is a nan in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_df['profit'] = _df['gross'] - _df['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.profit = np.where((_df.budget.isnull()) | (_df.gross.isnull()), np.nan, _df.profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14114037.355535554"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = _df['profit'].mean()\n",
    "stddev = _df['profit'].std()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-39028279.18019109, 10800204.469119987)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.norm.interval(alpha = 0.05,\n",
    "                   loc = mean, \n",
    "                   scale = stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#104263004.12575178\n",
    "#-48965307.24992396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as scs\n",
    "\n",
    "mean_ = _df.profit.mean()\n",
    "std_ = _df.profit.std()\n",
    "alpha = 0.05\n",
    "n = len(_df.dropna(subset = ['profit']))\n",
    "\n",
    "zscore = scs.norm.ppf(1-(alpha/2))\n",
    "\n",
    "max_ = mean_+ zscore * (std_/np.sqrt(n))\n",
    "min_ = mean_ - zscore * (std_/np.sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1111"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9248728.208643755, -37476802.91971486)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14114037.355535554"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9249157.512832018, -37477232.22390313)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus = mean - 1.96*(stddev/n**.5)\n",
    "\n",
    "\n",
    "plus = mean + 1.96*(stddev/n**.5)\n",
    "plus, minus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Your ability to answer the first question has the executive excited and now she has many other questions about the types of movies being made and the differences in those movies budgets and gross amounts.  Read through the questions below and determine what type of statistical test you should use for each question and write down the null and alternative hypothesis for those tests.    \n",
    "\n",
    "- Is there a realtionship between the number of facebook likes for a cast and the box office gross of the movie?\n",
    "- Do foreign films perform differently at the box office than non-foreign films?\n",
    "- Of all movies created are 40% rated R?\n",
    "- Is there a relationship between the language of a film and the content rating (G, PG, PG-13, R)of that film?\n",
    "- Is there a relationship between the content rating of a film and its budget? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a realtionship between the number of facebook likes for a cast and the box office gross of the movie? ####\n",
    "\n",
    "Number of Likes: Continuous\n",
    "Box office Gross: Continuous\n",
    "\n",
    "Relationship between two continuous values, test: \n",
    "\n",
    "Pearson Correlation CoEfficient\n",
    "or \n",
    "Linear Regression\n",
    "\n",
    "Is there a relationship between the content rating of a film and its budget?\n",
    "\n",
    "\n",
    "Test: \n",
    "    H0 No correlation\n",
    "    Ha There is correlation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167274881.23395962"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreign.sem(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do foreign films perform differently at the box office than non-foreign films? ####\n",
    "\n",
    "#foreign film box office revenue mean: Continuous\n",
    "#non-foreign box office revenue mean: Continuous\n",
    "\n",
    "#Compare two means of the revenue of two quantitative groups\n",
    "#two sample t-test of means \n",
    "\n",
    "\n",
    "#Test: \n",
    "    #H0 mean1-mean2 = 0\n",
    "    #Ha mean1-mean2 != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t-stat: ',\n",
       " -1.7095288156536121,\n",
       " 'degrees of freedom: ',\n",
       " 1388,\n",
       " 'critical-value',\n",
       " 1.6459521808844497,\n",
       " 'pvalue',\n",
       " 0.08757655539551701)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreign = _df[_df.language != 'English']['profit']\n",
    "domestic = _df[_df.language == 'English']['profit']\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "\n",
    "def independent_ttest(df1, df2, alpha):\n",
    "\n",
    "    #calculate means\n",
    "    mean1, mean2 = df1.mean(), df2.mean()\n",
    "\n",
    "    # calculate standard errors\n",
    "    se1, se2 = df1.sem(axis = 0), df2.sem(axis = 0)\n",
    "\n",
    "    # standard error on the difference between the samples\n",
    "    sed = np.sqrt(se1**2 + se2**2)\n",
    "    # calculate the t statistic\n",
    "    t_stat = ((df1.mean()) - (df2.mean()) )/ sed\n",
    "\n",
    "    # degrees of freedom (n1+n2)-2\n",
    "    dof = len(df1) + len(df2) - 2\n",
    "\n",
    "    # calculate the critical value\n",
    "    cv = stats.t.ppf(1.0 - alpha, dof)\n",
    "\n",
    "    # calculate the p-value\n",
    "    p = (1.0 - stats.t.cdf(abs(t_stat), dof)) * 2.0\n",
    "    \n",
    "    # return the good stuff\n",
    "    return 't-stat: ',t_stat, 'degrees of freedom: ',dof, 'critical-value', cv, 'pvalue', p\n",
    "\n",
    "cv = 1.6459521808844497\n",
    "t_stat = -1.7095288156536121\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "independent_ttest(foreign, domestic, alpha)\n",
    "\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_fail_to_reject(t_stat, cv, alpha):\n",
    "    if abs(t_stat) <= cv:\n",
    "        print ('Fail to reject the null hypothesis that the means are equal at a significance level of ', alpha, '.')\n",
    "    else:\n",
    "        print ('Reject the null hypothesis that the means are equal at a significance level of ', alpha, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "foreign = _df[_df.language != 'English']['profit']\n",
    "domestic = _df[_df.language == 'English']['profit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreign.dropna(inplace = True)\n",
    "domestic.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-6.233110236021216, pvalue=6.486026348275082e-10)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scs.ttest_ind(foreign, domestic) \n",
    "# two sample independent t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-176-f795f1e4b911>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-176-f795f1e4b911>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    p-value = 6.486026348275082e-10\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "t_stat = -6.233110236021216\n",
    "p-value = 6.486026348275082e-10\n",
    "alpha = 0.05\n",
    "\n",
    "reject_fail_to_reject(t_stat, cv, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Of all movies created are 40% rated R? ####\n",
    "\n",
    "proportion of movies\n",
    "specifically you want to do a two tail difference of proportions\n",
    "proportions always z test, there is no use of std\n",
    "\n",
    "\n",
    "Test:\n",
    "\n",
    "    H0 P = .40\n",
    "    Ha P != .40\n",
    "    prove it is not above or below .4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a relationship between the language of a film and the content rating (G, PG, PG-13, R)of that film? ####\n",
    "\n",
    "language: catergorical\n",
    "content rating: catergorical\n",
    "\n",
    "Two catergories to compare\n",
    "Chi Square, Frequency\n",
    "\n",
    "Test: \n",
    "    H0 no relationship\n",
    "    Ha relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-154-a0248981da82>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-154-a0248981da82>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    scs.chi2_contingency(language_rating)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "language_rating = _df['language','rating]'\n",
    "scs.chi2_contingency(language_rating) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a relationship between the content rating of a film and its budget?####\n",
    "\n",
    "Content Rating catergorical\n",
    "Budget is continuous \n",
    "\n",
    "H0 mean budget per catergory is =\n",
    "Ha at least one mean budget of a rating !=\n",
    "\n",
    "\n",
    "ANOVA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now that you have answered all of those questions, the excutive wants you to create a model that predicts the money a movie will make if it is released next year in the US. She wants to use this to evaluate different scripts and then decide which one has the largest revenue potential. Below is a list of potential features you could use in the model. Discuss the steps you would need to take in order to prepare the data for the model. Would you use all of these features in the model? Identify which features you might drop and why, and discuss the process you would use to determine this.  \n",
    "\n",
    "*Remember you want to be able to use this model to predict the box office gross of a film **before** anyone has seen it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- budget: The amount of money spent to make the movie\n",
    "- title_year: The year the movie first came out in the box office\n",
    "- years_old: How long has it been since the movie was released\n",
    "- genre: Each movie is assigned one genre category like action, horror, comedy.\n",
    "- avg_user_rating: This rating is taken from Rotten tomatoes, and is the average rating given to the movie by the audience. \n",
    "- actor_1_facebook_likes: The number of likes that the most popular actor in the movie has\n",
    "- total_cast_facebook_likes: The sum of likes for the three most popular actors in the movie\n",
    "- language: the orginal spoken language of the film\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_model = ols(fomrula = 'gross-cast_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title year or years old drop they would produce multicollinearity\n",
    "actor likes and cast likes facebook take one way becasue they correlate too much also could produce multicollinarity \n",
    "(you could keep one of each)\n",
    "\n",
    "rating is unknown because it is not out yet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Below is the summary output of a fitted OLS model.  Look at the summary of this OLS model and identify any key takeaways from it.  How â€˜goodâ€™ is this model? Which features help to explain the variance in the target variable? Which do not? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ols_summary.png\" style=\"withd:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew higher than one and kurtosis higher than three show it is highly skewed\n",
    "r2 shows there's not much correlation shown\n",
    "adjusted isn't much different\n",
    "pvalues, some less than 0.05 \n",
    "intersections \n",
    "\n",
    "skewness higher than 1 skewed \n",
    "higher than 1 positive skew\n",
    "less than -1 negative\n",
    "\n",
    "\n",
    "\n",
    "R2 low, very little variance is explained by your targets using the features that you have\n",
    "if p value is over 0.05 (level of significance can change, but in this case 0.05)\n",
    "p value is dependent on the over features\n",
    "\n",
    "if you drop a feature, it may change the p value and be less or more influential of your target \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "**Bayes Theorem**\n",
    "\n",
    "An advertising executive is studying television viewing habits of married men and women during prime time hours. Based on the past viewing records he has determined that during prime time wives are watching television 60% of the time. It has also been determined that when the wife is watching television, 40% of the time the husband is also watching. When the wife is not watching the television, 30% of the time the husband is watching the television. Find the probability that if the husband is watching the television, the wife is also watching the television."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the wife is also watching the television if the husband is watching the television, \n",
    "\n",
    "#P(A) = P(wife) = Wife watching\n",
    "#P(B) = P(husband) = Husband watching\n",
    "\n",
    "p_wife = .60\n",
    "p_wife_not = .40\n",
    "\n",
    "p_husband_given_wife = .40\n",
    "p_husband_given_not_wife = .30\n",
    "\n",
    "p_husband = ((p_husband_given_wife) * p_wife) + ((p_husband_given_not_wife)* p_wife_not)\n",
    "p_husband\n",
    "\n",
    "# P(B) = P(B|A)* P(A) + P(B|A') * P(A')\n",
    "\n",
    "\n",
    "\n",
    "#if denotes B\n",
    "#suppose denotes B\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A|B) is :  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "wife_given_husband = (p_husband_given_wife * p_wife)/p_husband\n",
    "\n",
    "\n",
    "# P(A|B)\n",
    "print ('P(A|B) is : ', wife_given_husband)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Explain what a type 1 error is and how does it relate to the significance level when doing a statistical test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A type 1 error is a false positive. (Meme example: A man beingn told he is pregnant) \n",
    "We Reject H0 when we should have failed to reject H0.  \n",
    "\n",
    "A type 2 error is a false negative. (Meme example: a woman is told she is not pregnant when clearly she is)\n",
    "When we Fail to Reject H0 even though we should have rejected H0. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
